{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load the pdf files from the path\n",
    "loader = DirectoryLoader('data/',glob=\"*.pdf\",loader_cls=PyPDFLoader)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#split text into chunks\n",
    "text_splitter  = RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)\n",
    "text_chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "                                   model_kwargs={'device':\"cpu\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#vectorstore\n",
    "vector_store = FAISS.from_documents(text_chunks,embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create llm\n",
    "llm = CTransformers(model=\"llama-2-7b-chat.ggmlv3.q4_0.bin\",model_type=\"llama\",\n",
    "                    config={'max_new_tokens':128,'temperature':0.01})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chain = ConversationalRetrievalChain.from_llm(llm=llm,chain_type='stuff',\n",
    "                                              retriever=vector_store.as_retriever(search_kwargs={\"k\":2}),\n",
    "                                              memory=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "st.title(\"HealthCare ChatBot üßëüèΩ‚Äç‚öïÔ∏è\")\n",
    "def conversation_chat(query):\n",
    "    result = chain({\"question\": query, \"chat_history\": st.session_state['history']})\n",
    "    st.session_state['history'].append((query, result[\"answer\"]))\n",
    "    return result[\"answer\"]\n",
    "\n",
    "def initialize_session_state():\n",
    "    if 'history' not in st.session_state:\n",
    "        st.session_state['history'] = []\n",
    "\n",
    "    if 'generated' not in st.session_state:\n",
    "        st.session_state['generated'] = [\"Hello! Ask me anything about ü§ó\"]\n",
    "\n",
    "    if 'past' not in st.session_state:\n",
    "        st.session_state['past'] = [\"Hey! üëã\"]\n",
    "\n",
    "def display_chat_history():\n",
    "    reply_container = st.container()\n",
    "    container = st.container()\n",
    "\n",
    "    with container:\n",
    "        with st.form(key='my_form', clear_on_submit=True):\n",
    "            user_input = st.text_input(\"Question:\", placeholder=\"Ask about your Mental Health\", key='input')\n",
    "            submit_button = st.form_submit_button(label='Send')\n",
    "\n",
    "        if submit_button and user_input:\n",
    "            output = conversation_chat(user_input)\n",
    "\n",
    "            st.session_state['past'].append(user_input)\n",
    "            st.session_state['generated'].append(output)\n",
    "\n",
    "    if st.session_state['generated']:\n",
    "        with reply_container:\n",
    "            for i in range(len(st.session_state['generated'])):\n",
    "                message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user', avatar_style=\"thumbs\")\n",
    "                message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"fun-emoji\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize session state\n",
    "initialize_session_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display chat history\n",
    "display_chat_history()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
